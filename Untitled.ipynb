{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e3a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the libraries necessary for data wrangling, prediction and result analysis\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n",
    "import torch\n",
    "from numba import cuda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8753e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde9db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q simpletransformers\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189cf999",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3fd51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47718725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\prate/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece7c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the GPU cache\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec82926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#29: बोत्सवाना + 12.1% अर्थव्यवस्था: बोत्सवाना...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'पदक के अलावा कुछ भी निराशा होने वाला है' अनुभ...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'बी' आर्क ... \"मेरा मतलब है, मैं ध्यान देने मे...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'मिडसोमर की मस्ती, लेकिन इस कहानी को बताने की ...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'मिडसोमर की मस्ती, लेकिन इस कहानी को बताने की ...</td>\n",
       "      <td>Opinion/Argumentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                    label\n",
       "0  #29: बोत्सवाना + 12.1% अर्थव्यवस्था: बोत्सवाना...                     News\n",
       "1  'पदक के अलावा कुछ भी निराशा होने वाला है' अनुभ...                     News\n",
       "2  'बी' आर्क ... \"मेरा मतलब है, मैं ध्यान देने मे...                    Other\n",
       "3  'मिडसोमर की मस्ती, लेकिन इस कहानी को बताने की ...  Information/Explanation\n",
       "4  'मिडसोमर की मस्ती, लेकिन इस कहानी को बताने की ...    Opinion/Argumentation"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "df = pd.read_csv('C:/Users/prate/Downloads/our_dataset_merged.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d410b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text\n",
      "900  संबंधित विषय 2 में से 1. इजराइल के प्रधान मंत्...\n",
      "901  संयुक्त राष्ट्र में बलि का बकरा के रूप में इज़...\n",
      "902  संरचनाओं के परिणाम: एक लंबा समय इतना बुरा नहीं...\n",
      "903  संशोधित एसटीटीएम पुस्तक आ चुकी है! आपके पास दो...\n",
      "904  सच्चा नेतृत्व लोगों को ऐसी जगह ले जाने के बारे...\n",
      "..                                                 ...\n",
      "995  हाइलाइट मोबाइल फोन की पहुंच दुनिया की तीन चौथा...\n",
      "996  हाउस इन द कंट्री: अंटार्कटिका हर सुबह उस नज़ार...\n",
      "997  हाय दोस्तों मैं दो अद्भुत साइटों पर दो उपहार द...\n",
      "998  हाय दोस्तों मैं दो अद्भुत साइटों पर दो उपहार द...\n",
      "999  हाय रॉबर्ट, या मुझे ग्राहम कहना चाहिए। मैंने प...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df[900:1000]\n",
    "test_df = test_df.drop(['label'],axis = 1)\n",
    "print(test_df)\n",
    "dev_df = df[:100]\n",
    "dev_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115751a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c554bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['News',\n",
       " 'Other',\n",
       " 'Information/Explanation',\n",
       " 'Opinion/Argumentation',\n",
       " 'Prose/Lyrical',\n",
       " 'Forum',\n",
       " 'Instruction',\n",
       " 'Legal']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of labels\n",
    "LABELS = df.label.unique().tolist()\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1608b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprateekg2050\u001b[0m (\u001b[33mlazy-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\prate\\xlm-robert\\wandb\\run-20221218_135843-hha5mai7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lazy-ai/Hindi-hyperparameter-search/runs/hha5mai7\" target=\"_blank\">training-and-saving-the-model</a></strong> to <a href=\"https://wandb.ai/lazy-ai/Hindi-hyperparameter-search\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/lazy-ai/Hindi-hyperparameter-search/runs/hha5mai7?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ebd8e4bca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Wandb\n",
    "wandb.init(project=\"Hindi-hyperparameter-search\", name=\"training-and-saving-the-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8cc163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how many steps will each epoch have\n",
    "# Num steps in epoch = training samples / batch size\n",
    "steps_per_epoch = int(579/8)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96340988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f23e1bdf37446b9b44cf8eb6f6ff118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prate\\anaconda3\\lib\\site-packages\\huggingface_hub-0.11.1-py3.8.egg\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prate\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'use_cuda' set to True when cuda is unavailable. Make sure CUDA is available or set use_cuda=False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14996\\3884615537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m roberta_base_model = ClassificationModel(\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;34m\"xlmroberta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"xlm-roberta-base\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_type, model_name, tokenizer_type, tokenizer_name, num_labels, weight, args, use_cuda, cuda_device, onnx_execution_provider, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cuda:{cuda_device}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    389\u001b[0m                     \u001b[1;34m\"'use_cuda' set to True when cuda is unavailable.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[1;34m\" Make sure CUDA is available or set use_cuda=False.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'use_cuda' set to True when cuda is unavailable. Make sure CUDA is available or set use_cuda=False."
     ]
    }
   ],
   "source": [
    "# Create a TransformerModel and evaluate during training\n",
    "epoch = 90\n",
    "\n",
    "roberta_base_model = ClassificationModel(\n",
    "        \"xlmroberta\", \"xlm-roberta-base\",\n",
    "        num_labels=len(LABELS),\n",
    "        use_cuda=True,\n",
    "        args= {\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"num_train_epochs\": epoch,\n",
    "            \"train_batch_size\":8,\n",
    "            \"learning_rate\": 1e-5,\n",
    "            # Use these parameters if you want to evaluate during training\n",
    "            \"evaluate_during_training\": True,\n",
    "            \"evaluate_during_training_steps\": steps_per_epoch*10,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"use_cached_eval_features\": True,\n",
    "            'reprocess_input_data': True,\n",
    "            \"labels_list\": LABELS,\n",
    "            # The following parameters (no_cache, no_save) are commented out if I want to save the model\n",
    "            \"no_cache\": True,\n",
    "            # Disable no_save: True if you want to save the model\n",
    "            \"no_save\": True,\n",
    "            \"max_seq_length\": 512,\n",
    "            \"save_steps\": -1,\n",
    "            # Only the trained model will be saved - to prevent filling all of the space\n",
    "            \"save_model_every_epoch\":False,\n",
    "            \"wandb_project\": 'Hindi-hyperparameter-search',\n",
    "            \"silent\": True,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Train the model and evaluate during training\n",
    "roberta_base_model.train_model(df, eval_df = dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fa546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
