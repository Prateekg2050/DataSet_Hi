{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba9ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the libraries necessary for data wrangling, prediction and result analysis\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n",
    "import torch\n",
    "from numba import cuda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q simpletransformers\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138350e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the GPU cache\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('')\n",
    "print(train_df)\n",
    "\n",
    "test_df = train_df[900:1000]\n",
    "test_df = test_df.drop(['label'],axis = 1)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of labels\n",
    "LABELS = train_df.label.unique().tolist()\n",
    "LABELS\n",
    "train_df['label']=train_df['label'].replace(['Other', 'Information/Explanation', 'News', 'Instruction', 'Opinion/Argumentation', 'Forum', 'Prose/Lyrical', 'Legal', 'Promotion'],[0,1,2,3,4,5,6,7,8])\n",
    "dev_df = train_df[:100]\n",
    "print(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83639835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Wandb\n",
    "wandb.init(project=\"Hindi-hyperparameter-search\", name=\"training-and-saving-the-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many steps will each epoch have\n",
    "# Num steps in epoch = training samples / batch size\n",
    "steps_per_epoch = int(579/8)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TransformerModel and evaluate during training\n",
    "epoch = 90\n",
    "\n",
    "roberta_base_model = ClassificationModel(\n",
    "        \"xlmroberta\", \"TajaKuzman/xlm-roberta-base-multilingual-text-genres\",\n",
    "        use_cuda=True,\n",
    "        args= {\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"num_train_epochs\": epoch,\n",
    "            \"train_batch_size\":8,\n",
    "            \"learning_rate\": 1e-5,\n",
    "            # Use these parameters if you want to evaluate during training\n",
    "            \"evaluate_during_training\": True,\n",
    "            \"evaluate_during_training_steps\": steps_per_epoch*10,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"use_cached_eval_features\": True,\n",
    "            'reprocess_input_data': True,\n",
    "            # \"labels_list\": LABELS,\n",
    "            # The following parameters (no_cache, no_save) are commented out if I want to save the model\n",
    "            \"no_cache\": True,\n",
    "            # Disable no_save: True if you want to save the model\n",
    "            \"no_save\": True,\n",
    "            \"max_seq_length\": 512,\n",
    "            \"save_steps\": -1,\n",
    "            # Only the trained model will be saved - to prevent filling all of the space\n",
    "            \"save_model_every_epoch\":False,\n",
    "            \"wandb_project\": 'Hindi-hyperparameter-search',\n",
    "            \"silent\": True,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Train the model and evaluate during training\n",
    "roberta_base_model.train_model(train_df, eval_df = dev_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
